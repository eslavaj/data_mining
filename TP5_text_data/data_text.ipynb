{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.jars = [\"lsa.jar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://jeslava-pc:4041\n",
       "SparkContext available as 'sc' (version = 2.4.4, master = local[*], app id = local-1584473017233)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import com.cloudera.datascience.lsa._\n",
       "import com.cloudera.datascience.lsa.ParseWikipedia._\n",
       "import com.cloudera.datascience.lsa.RunLSA._\n",
       "import org.apache.spark.mllib.linalg._\n",
       "import org.apache.spark.mllib.linalg.distributed.RowMatrix\n",
       "import breeze.linalg.{DenseMatrix=>BDenseMatrix, DenseVector=>BDenseVector, SparseVector=>BSparseVector}\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.cloudera.datascience.lsa._\n",
    "import com.cloudera.datascience.lsa.ParseWikipedia._\n",
    "import com.cloudera.datascience.lsa.RunLSA._\n",
    "import org.apache.spark.mllib.linalg._\n",
    "import org.apache.spark.mllib.linalg.distributed.RowMatrix\n",
    "import breeze.linalg.{DenseMatrix => BDenseMatrix, DenseVector => BDenseVector, SparseVector => BSparseVector}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wikixmlfile: String = file:///home/jeslava/msata/cnam_RCP216/data_mining/TP5_text_data/data/enwiki.xml\n",
       "sampleSize: Double = 0.3\n",
       "xmlPages: org.apache.spark.rdd.RDD[String] = PartitionwiseSampledRDD[2] at sample at <console>:43\n",
       "res0: Array[String] =\n",
       "Array(<page>\n",
       "    <title>AfghanistanPeople</title>\n",
       "    <ns>0</ns>\n",
       "    <id>15</id>\n",
       "    <redirect title=\"Demographics of Afghanistan\" />\n",
       "    <revision>\n",
       "      <id>616420354</id>\n",
       "      <parentid>135089040</parentid>\n",
       "      <timestamp>2014-07-10T19:18:43Z</timestamp>\n",
       "      <contributor>\n",
       "        <username>RussBot</username>\n",
       "        <id>279219</id>\n",
       "      </contributor>\n",
       "      <minor />\n",
       "      <comment>Robot: Fixing double redirect to [[Demographics of Afghanistan]]</comment>\n",
       "      <model>wikitext</model>\n",
       "      <format>text/x-wiki</format>\n",
       "      <text xml..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*Load a set of articles from wikipedia in memory, note that this set of articles has been\n",
    "previously downloaded*/\n",
    "val wikixmlfile = \"file:///home/jeslava/msata/cnam_RCP216/data_mining/TP5_text_data/data/enwiki.xml\"\n",
    "val sampleSize = 0.3\n",
    "val xmlPages = ParseWikipedia.readFile(wikixmlfile, sc).sample(false, sampleSize, 11L)\n",
    "xmlPages.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plainText: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[4] at flatMap at <console>:40\n",
       "res1: Array[(String, String)] =\n",
       "Array((Autism,\"Autism\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Autism is a neurodevelopmental disorder characterized by impaired social interaction, verbal and non-verbal communication, and restricted and repetitive behavior. Parents usually notice signs in the first two years of their child's life.  The signs typically develop gradually, but some children with autism will reach their developmental milestones at a normal pace and then regress.\n",
       "Autism is highly heritable, but the cause includes both environmental factors and genetic susceptibility.  In rare cases, autism is strongly associated with agents that cause birth defects.  Controversies surround other proposed environmental caus..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val plainText = xmlPages.filter(_ != null).flatMap(ParseWikipedia.wikiXmlToPlainText)\n",
    "plainText.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stopWords: scala.collection.immutable.Set[String] = Set(down, it's, that's, for, further, she'll, any, there's, this, haven't, in, ought, myself, have, your, off, once, i'll, are, is, his, why, too, why's, am, than, isn't, didn't, himself, but, you're, below, what, would, i'd, if, you'll, own, they'll, up, we're, they'd, so, our, do, all, him, ours\tourselves, had, nor, before, it, a, she's, as, hadn't, because, has, she, yours, or, above, yourself, herself, she'd, such, they, each, can't, don't, i, until, that, out, he's, cannot, to, we've, hers, you, did, let's, most, here, these, hasn't, was, there, when's, shan't, doing, at, through, been, over, i've, on, being, same, how, whom, my, after, who, itself, me, them, by, then, couldn't, he, should, few, wasn't, again, while, their, not, w..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stopWords = sc.broadcast(ParseWikipedia\n",
    "                         .loadStopWords(\"/home/jeslava/msata/cnam_RCP216/data_mining/TP5_text_data/deps/lsa/src/main/resources/stopwords.txt\")).value\n",
    "val lemmatized = plainText.mapPartitions(iter => {\n",
    "           val pipeline = ParseWikipedia.createNLPPipeline();\n",
    "           iter.map{ case(title, contents) =>\n",
    "                         (title, ParseWikipedia.plainTextToLemmas(contents, stopWords, pipeline))};\n",
    "       }).cache()\n",
    "\n",
    "lemmatized.take(2)\n",
    "val filtered = lemmatized.filter(_._2.size > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of terms: 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numTerms: Int = 1000\n",
       "termDocMatrix: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[17] at map at ParseWikipedia.scala:64\n",
       "termIds: scala.collection.Map[Int,String] = Map(645 -> improve, 892 -> identify, 69 -> court, 809 -> time, 629 -> simple, 365 -> lower, 138 -> size, 760 -> american, 101 -> agree, 479 -> child, 347 -> currently, 846 -> relatively, 909 -> film, 333 -> though, 628 -> house, 249 -> differ, 893 -> rise, 518 -> transport, 962 -> located, 468 -> october, 234 -> george, 941 -> distance, 0 -> rate, 777 -> debate, 555 -> remain, 666 -> back, 88 -> point, 481 -> company, 352 -> pay, 408 -> social, 977 -> obtain, 170 -> join, 523 -> legal, 582 -> space, 762 -> characteristic, 115 -> show, 683 -> still, 730 -> use, 217 -> description, 276 -> pet..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*Calculate TF-IDF matrix*/\n",
    "val numTerms = 1000 // nombre de termes à garder (les plus fréquents)\n",
    "val (termDocMatrix, termIds, docIds, idfs) = ParseWikipedia.termDocumentMatrix(filtered, stopWords, numTerms, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: termDocMatrix.type = MapPartitionsRDD[17] at map at ParseWikipedia.scala:64\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termDocMatrix.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mat: org.apache.spark.mllib.linalg.distributed.RowMatrix = org.apache.spark.mllib.linalg.distributed.RowMatrix@1123199a\n",
       "k: Int = 200\n",
       "svd: org.apache.spark.mllib.linalg.SingularValueDecomposition[org.apache.spark.mllib.linalg.distributed.RowMatrix,org.apache.spark.mllib.linalg.Matrix] =\n",
       "SingularValueDecomposition(org.apache.spark.mllib.linalg.distributed.RowMatrix@750b8270,[0.9008761596036255,0.7226773744473789,0.6829274782494884,0.49254083729171805,0.40010799137301467,0.3817621668956867,0.37013433486264996,0.3609104488907344,0.35245175882849533,0.35160537076856724,0.3394133124817201,0.3369745431839872,0.33352095472304993,0.33222331184216275,0.3283206911748484,0.32148845077892735,0.3179134202958888,0.3139892824615763,0.30868416996314774,0.30585183372151775,0.3052117000251546,0.2975083905..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*Calculate LSA*/\n",
    "val mat = new RowMatrix(termDocMatrix)\n",
    "val k = 200 // nombre de valeurs singulières à garder\n",
    "val svd = mat.computeSVD(k, computeU = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept terms: code, character, computer, language, science, design, unit, law, datum, game\n",
      "Concept docs: Currency code, Code, Code of Hammurabi, Code coverage, Design Science License, Control character, BLM, ASCII, List of country calling codes, Cipher\n",
      "\n",
      "Concept terms: code, significantly, somewhat, unlike, possibly, powerful, toward, heavily, entirely, quickly\n",
      "Concept docs: Currency code, Biathlon World Championships, List of Olympic medalists in biathlon, Antipope Victor IV, Alfonso IV, Aberdeen Bestiary, BLM, Cucurbitaceae, Christopher Báthory, List of anthropologists\n",
      "\n",
      "Concept terms: unit, code, significantly, somewhat, unlike, toward, powerful, quickly, entirely, slightly\n",
      "Concept docs: Astronomical Units, Currency code, Conversion of units, Unit of alcohol, Control unit, British thermal unit, Candela, Byte, Biathlon World Championships, List of Olympic medalists in biathlon\n",
      "\n",
      "Concept terms: space, david, complete, set, real, distance, son, game, object, function\n",
      "Concept docs: David Bowman (Space Odyssey), Complete metric space, Amnon, Astronaut, Dimension, Convex set, Abiathar, Catherine Coleman, David Angell, David Thompson (explorer)\n",
      "\n",
      "Concept terms: government, britain, american, council, party, population, king, island, country, president\n",
      "Concept docs: Britain, Bundesrat, Government of the Cocos (Keeling) Islands, Demographics of Antigua and Barbuda, Alexander III, Transportation in American Samoa, Cretin, Brittonic, Civil Rights Act, Coalition government\n",
      "\n",
      "Concept terms: film, creation, song, king, american, game, iii, band, charles, music\n",
      "Concept docs: Creation, Cinema, Alexander III, Charles V, Alfonso Cuarón, Alexander II, Body, Character, David Fincher, Cretin\n",
      "\n",
      "Concept terms: government, party, game, country, rights, civil, population, total, city, president\n",
      "Concept docs: Government of the Cocos (Keeling) Islands, Civil Rights Act, Coalition government, Politics of Estonia, Telecommunications in the Democratic Republic of the Congo, Telecommunications in Chad, Telecommunications in Equatorial Guinea, European United Left–Nordic Green Left, Politics of the Cook Islands, Central African Republic\n",
      "\n",
      "Concept terms: council, king, iii, theory, charles, god, church, refer, word, german\n",
      "Concept docs: Bundesrat, Alexander III, Alexander II, Charles V, Complexity theory, Agis, Alfonso VI, Alexander IV, Cervical mucus method, Council of Chalcedon\n",
      "\n",
      "Concept terms: creation, song, band, theory, collection, film, music, class, body, star\n",
      "Concept docs: Creation, Collection, Cinema, Body, Creation myth, Complexity theory, Class, Constellations (journal), Boy band, Design Science License\n",
      "\n",
      "Concept terms: iii, king, game, russian, die, son, charles, defaultsort, star, battle\n",
      "Concept docs: Alexander III, Alexander II, Agis, Alfonso VI, Alexander IV, Amyntas III of Macedon, Ahmed III, Afonso V of Portugal, Agnes of Merania, Charles V\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topConceptTerms: Seq[Seq[(String, Double)]] = ArrayBuffer(ArraySeq((code,0.9945555353589379), (character,0.021694693736805312), (computer,0.019315520996154092), (language,0.017845648122745045), (science,0.016067706179285227), (design,0.015053877350772345), (unit,0.014929352494077163), (law,0.01479401486602408), (datum,0.014623734628316062), (game,0.013144710881486521)), ArraySeq((code,0.057136178940563394), (significantly,-0.0038646926388318723), (somewhat,-0.004357191678489329), (unlike,-0.004424123115154138), (possibly,-0.004568215756154709), (powerful,-0.004644885612657312), (toward,-0.004646078151510812), (heavily,-0.004655637801651445), (entirely,-0.004664205215766954), (quickly,-0.00479863011295463)), ArraySeq((unit,0.45426610702045955), (code,0.07770892827738134), (significantly,..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*Show the most repeated themes and the documents where they are more present*/\n",
    "val topConceptTerms = RunLSA.topTermsInTopConcepts(svd, 10, 10, termIds)\n",
    "val topConceptDocs = RunLSA.topDocsInTopConcepts(svd, 10, 10, docIds)\n",
    "for ((terms, docs) <- topConceptTerms.zip(topConceptDocs)) {\n",
    "          println(\"Concept terms: \" + terms.map(_._1).mkString(\", \"));\n",
    "          println(\"Concept docs: \" + docs.map(_._1).mkString(\", \"));\n",
    "          println();\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
