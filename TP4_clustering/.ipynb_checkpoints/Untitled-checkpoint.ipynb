{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.packages = [\"org.vegas-viz:vegas_2.11:0.3.11\", \"org.vegas-viz:vegas-spark_2.11:0.3.11\"]\n",
    "launcher.master = \"local[4]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://wifi-auditeur-368.cnam.fr:4040\n",
       "SparkContext available as 'sc' (version = 2.4.4, master = local[4], app id = local-1583866992432)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Row\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "import org.apache.spark.mllib.util.KMeansDataGenerator\n",
       "donneesGenerees: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[3] at map at <console>:32\n",
       "res0: Array[org.apache.spark.sql.Row] = Array([[6.851431892838329,5.516447693896727]], [[-4.295988305021189,-4.831902144635173]])\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import org.apache.spark.mllib.util.KMeansDataGenerator\n",
    "\n",
    "// Générer les données\n",
    "val donneesGenerees = KMeansDataGenerator.generateKMeansRDD(sc, 1000, 5, 2, 5, 1)\n",
    "                                                .map(l => Vectors.dense(l))\n",
    "                                                .map(v => Row(v))\n",
    "donneesGenerees.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|features                                 |\n",
      "+-----------------------------------------+\n",
      "|[6.851431892838329,5.516447693896727]    |\n",
      "|[-4.295988305021189,-4.831902144635173]  |\n",
      "|[2.466261424212494,4.360426802469256]    |\n",
      "|[-3.6929582575126862,-6.342163511120067] |\n",
      "|[0.40109889970226975,6.603993964561202]  |\n",
      "|[7.459651912743491,4.835501449876057]    |\n",
      "|[-4.700311848077538,-6.473414666742812]  |\n",
      "|[1.7714851259762026,2.820426332188302]   |\n",
      "|[-2.6229150593060164,-6.2560724387559725]|\n",
      "|[-0.2488022191305468,8.303237208697512]  |\n",
      "|[7.09527856586733,5.391719071881441]     |\n",
      "|[-4.1093962887920155,-4.694216844940949] |\n",
      "|[2.432021563423027,2.493119849340497]    |\n",
      "|[-2.3592814771450565,-7.270336546373527] |\n",
      "|[0.15241818421045839,6.509821155247765]  |\n",
      "|[7.4662523011015445,4.436875066957234]   |\n",
      "|[-5.438322877988338,-4.9668282822927665] |\n",
      "|[1.8326398476752015,2.750501464430018]   |\n",
      "|[-1.8619822493373936,-7.944879647731648] |\n",
      "|[-0.466115292913019,6.697896784762749]   |\n",
      "+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.ml.linalg.SQLDataTypes.VectorType\n",
       "schemaVecteurs: org.apache.spark.sql.types.StructType = StructType(StructField(features,org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7,true))\n",
       "vecteursGroupesDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [features: vector]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Construction d'un DataFrame à partir du RDD\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.ml.linalg.SQLDataTypes.VectorType\n",
    "\n",
    "val schemaVecteurs = StructType(Seq(StructField(\"features\", VectorType, true)))\n",
    "val vecteursGroupesDF = spark.createDataFrame(donneesGenerees, schemaVecteurs).cache()\n",
    "vecteursGroupesDF.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.linalg.Vector\n",
       "import org.apache.spark.sql.functions.udf\n",
       "first: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n",
       "second: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.functions.udf\n",
    "// Extrait le premier scalaire d'un vecteur et le place dans une colonne\n",
    "val first = udf((v: Vector) => v.toArray(0))\n",
    "// Extrait le deuxième scalaire d'un vecteur et le place dans une colonne\n",
    "val second = udf((v: Vector) => v.toArray(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "render: vegas.render.ShowHTML = <function1>\n",
       "import vegas._\n",
       "import vegas.data.External._\n",
       "import vegas.sparkExt._\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Import des bibliothèques de Vegas\n",
    "implicit val render = vegas.render.ShowHTML(s => print(\"%html \" + s))\n",
    "\n",
    "import vegas._\n",
    "import vegas.data.External._\n",
    "import vegas.sparkExt._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "points: org.apache.spark.sql.DataFrame = [features: vector, x: double ... 1 more field]\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Construction du nuage de points\n",
    "val points = vecteursGroupesDF.withColumn(\"x\", first($\"features\")).withColumn(\"y\", second($\"features\"))\n",
    "Vegas(\"Données initiales\").withDataFrame(points).mark(Point).encodeX(\"x\", Quant).encodeY(\"y\", Quant).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.clustering.KMeans\n",
       "kmeans: org.apache.spark.ml.clustering.KMeans = kmeans_7d7961645e07\n",
       "modele: org.apache.spark.ml.clustering.KMeansModel = kmeans_7d7961645e07\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// K-mean with k-means || initialization\n",
    "import org.apache.spark.ml.clustering.KMeans\n",
    "\n",
    "// Appliquer k-means\n",
    "val kmeans = new KMeans().setK(5).setMaxIter(200).setSeed(2L)\n",
    "val modele = kmeans.fit(vecteursGroupesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.012568296756314948,7.526532076239347]\n",
      "[-3.09577594145568,-7.575565466974656]\n",
      "[-3.6775192699330796,-5.739050211500434]\n",
      "[6.476504032626164,4.539774830579849]\n",
      "[2.2726021783591652,3.5068947661773584]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "wsse: Double = 977.923902493241\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Évaluer la classification par la somme des inerties intra-classe\n",
    "val wsse = modele.computeCost(vecteursGroupesDF)\n",
    "\n",
    "// Afficher les centres des groupes\n",
    "modele.clusterCenters.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|[6.85143189283832...|         3|\n",
      "|[-4.2959883050211...|         2|\n",
      "|[2.46626142421249...|         4|\n",
      "|[-3.6929582575126...|         2|\n",
      "|[0.40109889970226...|         0|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "resultat: org.apache.spark.sql.DataFrame = [features: vector, prediction: int]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Trouver l'indice de groupe pour chaque donnée\n",
    "val resultat = modele.transform(vecteursGroupesDF)\n",
    "resultat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "points: org.apache.spark.sql.DataFrame = [features: vector, prediction: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val points = resultat.withColumn(\"x\", first($\"features\")).withColumn(\"y\", second($\"features\"))\n",
    "Vegas(\"K-Means\").withDataFrame(points).mark(Point).encodeX(\"x\", Quant).encodeY(\"y\", Quant).encodeColor(\"prediction\", Nom).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kmeans: org.apache.spark.ml.clustering.KMeans = kmeans_544d3ba640ce\n",
       "modele: org.apache.spark.ml.clustering.KMeansModel = kmeans_544d3ba640ce\n",
       "resultat: org.apache.spark.sql.DataFrame = [features: vector, prediction: int]\n",
       "points: org.apache.spark.sql.DataFrame = [features: vector, prediction: int ... 2 more fields]\n",
       "wsse: Double = 873.2579094097384\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Appliquer k-means\n",
    "val kmeans = new KMeans().setK(6).setMaxIter(200).setSeed(1L)\n",
    "val modele = kmeans.fit(vecteursGroupesDF)\n",
    "val resultat = modele.transform(vecteursGroupesDF)\n",
    "val points = resultat.withColumn(\"x\", first($\"features\")).withColumn(\"y\", second($\"features\"))\n",
    "Vegas(\"K-Means\").withDataFrame(points).mark(Point).encodeX(\"x\", Quant).encodeY(\"y\", Quant).encodeColor(\"prediction\", Nom).show\n",
    "// Évaluer la classification par la somme des inerties intra-classe\n",
    "val wsse = modele.computeCost(vecteursGroupesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kmeans: org.apache.spark.ml.clustering.KMeans = kmeans_b3e34e20ead8\n",
       "modele: org.apache.spark.ml.clustering.KMeansModel = kmeans_b3e34e20ead8\n",
       "resultat: org.apache.spark.sql.DataFrame = [features: vector, prediction: int]\n",
       "points: org.apache.spark.sql.DataFrame = [features: vector, prediction: int ... 2 more fields]\n",
       "wsse: Double = 2986.7590732647636\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// init random\n",
    "// Appliquer k-means\n",
    "val kmeans = new KMeans().setK(5).setMaxIter(200).setSeed(2L).setInitMode(\"random\")\n",
    "val modele = kmeans.fit(vecteursGroupesDF)\n",
    "val resultat = modele.transform(vecteursGroupesDF)\n",
    "val points = resultat.withColumn(\"x\", first($\"features\")).withColumn(\"y\", second($\"features\"))\n",
    "Vegas(\"K-Means\").withDataFrame(points).mark(Point).encodeX(\"x\", Quant).encodeY(\"y\", Quant).encodeColor(\"prediction\", Nom).show\n",
    "// Évaluer la classification par la somme des inerties intra-classe\n",
    "val wsse = modele.computeCost(vecteursGroupesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   transformedVector|\n",
      "+--------------------+\n",
      "|[6.85143189283832...|\n",
      "|[-4.2959883050211...|\n",
      "|[2.46626142421249...|\n",
      "|[-3.6929582575126...|\n",
      "|[0.40109889970226...|\n",
      "|[7.45965191274349...|\n",
      "|[-4.7003118480775...|\n",
      "|[1.77148512597620...|\n",
      "|[-2.6229150593060...|\n",
      "|[-0.2488022191305...|\n",
      "|[7.09527856586733...|\n",
      "|[-4.1093962887920...|\n",
      "|[2.43202156342302...|\n",
      "|[-2.3592814771450...|\n",
      "|[0.15241818421045...|\n",
      "|[7.46625230110154...|\n",
      "|[-5.4383228779883...|\n",
      "|[1.83263984767520...|\n",
      "|[-1.8619822493373...|\n",
      "|[-0.4661152929130...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.ElementwiseProduct\n",
       "transformingVector: org.apache.spark.ml.linalg.Vector = [1.0,3.0]\n",
       "transformer: org.apache.spark.ml.feature.ElementwiseProduct = elemProd_1d482d3d6c6f\n",
       "vecteursGroupesDF_tmp: org.apache.spark.sql.DataFrame = [features: vector, transformedVector: vector]\n",
       "trans_vecteursGroupesDF: org.apache.spark.sql.DataFrame = [transformedVector: vector]\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.ElementwiseProduct\n",
    "val transformingVector = Vectors.dense(1, 3.0)\n",
    "val transformer = new ElementwiseProduct()\n",
    "  .setScalingVec(transformingVector)\n",
    "  .setInputCol(\"features\")\n",
    "  .setOutputCol(\"transformedVector\")\n",
    "\n",
    "// Batch transform the vectors to create new column:\n",
    "val vecteursGroupesDF_tmp = transformer.transform(vecteursGroupesDF)\n",
    "val trans_vecteursGroupesDF = vecteursGroupesDF_tmp.select(\"transformedVector\")\n",
    "trans_vecteursGroupesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kmeans: org.apache.spark.ml.clustering.KMeans = kmeans_b68d4838f4df\n",
       "modele: org.apache.spark.ml.clustering.KMeansModel = kmeans_b68d4838f4df\n",
       "resultat: org.apache.spark.sql.DataFrame = [transformedVector: vector, prediction: int]\n",
       "points: org.apache.spark.sql.DataFrame = [transformedVector: vector, prediction: int ... 2 more fields]\n",
       "wsse: Double = 6914.1401525601805\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// init random\n",
    "// Appliquer k-means\n",
    "val kmeans = new KMeans().setK(5).setMaxIter(200).setSeed(2L).setFeaturesCol(\"transformedVector\")\n",
    "val modele = kmeans.fit(trans_vecteursGroupesDF)\n",
    "val resultat = modele.transform(trans_vecteursGroupesDF)\n",
    "val points = resultat.withColumn(\"x\", first($\"transformedVector\")).withColumn(\"y\", second($\"transformedVector\"))\n",
    "Vegas(\"K-Means\").withDataFrame(points).mark(Point).encodeX(\"x\", Quant).encodeY(\"y\", Quant).encodeColor(\"prediction\", Nom).show\n",
    "// Évaluer la classification par la somme des inerties intra-classe\n",
    "val wsse = modele.computeCost(trans_vecteursGroupesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
